<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="James E. Pustejovsky" />

<meta name="date" content="2026-02-01" />

<title>Wald tests of multiple-constraint null hypotheses</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Wald tests of multiple-constraint null
hypotheses</h1>
<h4 class="author">James E. Pustejovsky</h4>
<h4 class="date">2026-02-01</h4>


<div id="TOC">
<ul>
<li><a href="#the-wald-test-function" id="toc-the-wald-test-function"><span class="toc-section-number">1</span> The Wald test function</a>
<ul>
<li><a href="#testing-treatment-effects" id="toc-testing-treatment-effects"><span class="toc-section-number">1.1</span> Testing treatment effects</a></li>
<li><a href="#constrain_zero" id="toc-constrain_zero"><span class="toc-section-number">1.2</span>
<code>constrain_zero()</code></a></li>
<li><a href="#constrain_equal" id="toc-constrain_equal"><span class="toc-section-number">1.3</span>
<code>constrain_equal()</code></a></li>
</ul></li>
<li><a href="#testing-an-interaction" id="toc-testing-an-interaction"><span class="toc-section-number">2</span> Testing an interaction</a>
<ul>
<li><a href="#lists-of-constraints" id="toc-lists-of-constraints"><span class="toc-section-number">2.1</span> Lists of constraints</a></li>
</ul></li>
<li><a href="#pairwise-t-tests" id="toc-pairwise-t-tests"><span class="toc-section-number">3</span> Pairwise t-tests</a></li>
<li><a href="#remark" id="toc-remark"><span class="toc-section-number">4</span> Remark</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<p>Version 0.5.0 of <code>clubSandwich</code> introduced a new syntax
for <code>Wald_test()</code>, a function for conducting tests of
multiple-constraint hypotheses. In previous versions, this function was
poorly documented and, consequently, probably little used. This vignette
will demonstrate the new syntax.</p>
<p>For purposes of illustration, I will use the <code>STAR</code> data
(available in the <code>AER</code> package), which is drawn from a
randomized trial evaluating the effects of elementary school class size
on student achievement. The data consist of individual-level measures
for students in each of several dozen schools. For purposes of
illustration, I will look at effects on math performance in first grade.
Treatment conditions (the variable called <code>stark</code>) were
assigned at the classroom level, and consisted of either a) a
regular-size class, b) a small-size class, or c) a regular-size class
but with the addition of a teacher’s aide. In all of what follows, I
will cluster standard errors by school in order to allow for
generalization to a super-population of schools.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(clubSandwich)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">data</span>(STAR, <span class="at">package =</span> <span class="st">&quot;AER&quot;</span>)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># clean up a few variables</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="fu">levels</span>(STAR<span class="sc">$</span>stark)[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="st">&quot;aide&quot;</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="fu">levels</span>(STAR<span class="sc">$</span>schoolk)[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="st">&quot;urban&quot;</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>STAR <span class="ot">&lt;-</span> <span class="fu">subset</span>(STAR, </span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>               <span class="sc">!</span><span class="fu">is.na</span>(schoolidk),</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>               <span class="at">select =</span> <span class="fu">c</span>(schoolidk, schoolk, stark, gender, ethnicity, math1, lunchk))</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="fu">head</span>(STAR)</span></code></pre></div>
<pre><code>##      schoolidk  schoolk   stark gender ethnicity math1   lunchk
## 1137        63    rural   small female      cauc   538 non-free
## 1143        20 suburban   small female      afam   592 non-free
## 1183        19    urban    aide   male      afam    NA     free
## 1277        69    rural regular   male      cauc   584 non-free
## 1292        79    rural   small   male      cauc   545     free
## 1308         5    rural regular   male      cauc   553     free</code></pre>
<div id="the-wald-test-function" class="section level1" number="1">
<h1><span class="header-section-number">1</span> The Wald test
function</h1>
<p>The <code>Wald_test()</code> function can be used to conduct
hypothesis tests that involve multiple constraints on the regression
coefficients. Consider a linear model for an outcome <span class="math inline">\(Y_{ij}\)</span> regressed on a <span class="math inline">\(1 \times p\)</span> row vector of predictors <span class="math inline">\(\mathbf{x}_{ij}\)</span> (which might include a
constant intercept term): <span class="math display">\[
Y_{ij} = \mathbf{x}_{ij} \boldsymbol\beta + \epsilon_{ij}
\]</span> The regression coefficient vector is <span class="math inline">\(\boldsymbol\beta\)</span>. In quite general terms,
a set of constraints on the regression coefficient vector can be
expressed in terms of a <span class="math inline">\(q \times p\)</span>
matrix <span class="math inline">\(\mathbf{C}\)</span>, where each row
of <span class="math inline">\(\mathbf{C}\)</span> corresponds to one
constraint. A joint null hypothesis is then <span class="math inline">\(H_0: \mathbf{C} \boldsymbol\beta =
\mathbf{0}\)</span>, where <span class="math inline">\(\mathbf{0}\)</span> is a <span class="math inline">\(q \times 1\)</span> vector of zeros.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>Wald-type test are based on the test statistic <span class="math display">\[
Q = \left(\mathbf{C}\boldsymbol{\hat\beta}\right)&#39; \left(\mathbf{C}
\mathbf{V}^{CR} \mathbf{C}&#39;\right)^{-1}
\left(\mathbf{C}\boldsymbol{\hat\beta}\right),
\]</span> where <span class="math inline">\(\boldsymbol{\hat\beta}\)</span> is the estimated
regression coefficient vector and <span class="math inline">\(\mathbf{V}^{CR}\)</span> is a cluster-robust
variance matrix. If the number of clusters is sufficiently large, then
the distribution of <span class="math inline">\(Q\)</span> under the
null hypothesis is approximately <span class="math inline">\(\chi^2(q)\)</span>. <span class="citation">Tipton
&amp; Pustejovsky (2015)</span> investigated a wide range of other
approximations to the null distribution of <span class="math inline">\(Q\)</span>, many of which are included as options
in <code>Wald_test()</code>. Based on a large simulation, they (…er…we…)
recommended a method called the “approximate Hotelling’s <span class="math inline">\(T^2\)</span>-Z” test, or “AHZ.” This test
approximates the distribution of <span class="math inline">\(Q /
q\)</span> by a <span class="math inline">\(T^2\)</span> distribution,
which is a multiple of an <span class="math inline">\(F\)</span>
distribution, with numerator degrees of freedom <span class="math inline">\(q\)</span> and denominator degrees of freedom
based on a generalization of the Satterthwaite approximation.</p>
<p>The <code>Wald_test()</code> function has three main arguments:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">args</span>(Wald_test)</span></code></pre></div>
<pre><code>## function (obj, constraints, vcov, null_constant = 0, test = &quot;HTZ&quot;, 
##     tidy = FALSE, adjustment_method = &quot;none&quot;, ...) 
## NULL</code></pre>
<ul>
<li>The <code>obj</code> argument is used to specify the estimated
regression model on which to perform the test,</li>
<li>the <code>constraints</code> argument is a <span class="math inline">\(\mathbf{C}\)</span> matrix expressing the set of
constraints to test, and</li>
<li>the <code>vcov</code> argument is a cluster-robust variance matrix,
which is used to construct the test statistic. (Alternately,
<code>vcov</code> can be the type of cluster-robust variance matrix to
construct, in which case it will be computed internally.)</li>
</ul>
<p>By default, <code>Wald_test()</code> will use the HTZ small-sample
approximation. Other options are available (via the <code>test</code>
argument) but not recommended for routine use. The optional
<code>tidy</code> argument will be demonstrated below.</p>
<div id="testing-treatment-effects" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Testing treatment
effects</h2>
<p>Returning to the STAR data, let’s suppose we want to examine
differences in math performance across class sizes. This can be done
with a simple linear regression model, while clustering the standard
errors by <code>schoolidk</code>. The estimating equation is <span class="math display">\[
\left(\text{Math}\right)_{ij} = \beta_0 + \beta_1
\left(\text{small}\right)_{ij} + \beta_2 \left(\text{aide}\right)_{ij} +
e_{ij},
\]</span> which can be estimated in R as follows:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>lm_trt <span class="ot">&lt;-</span> <span class="fu">lm</span>(math1 <span class="sc">~</span> stark, <span class="at">data =</span> STAR)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>V_trt <span class="ot">&lt;-</span> <span class="fu">vcovCR</span>(lm_trt, <span class="at">cluster =</span> STAR<span class="sc">$</span>schoolidk, <span class="at">type =</span> <span class="st">&quot;CR2&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="fu">coef_test</span>(lm_trt, <span class="at">vcov =</span> V_trt)</span></code></pre></div>
<pre><code>## Alternative hypothesis: two-sided 
##        Coef. Estimate   SE Null value  t-stat d.f. (Satt) p-val (Satt) Sig.
##  (Intercept)  531.727 2.78          0 191.506        59.9       &lt;0.001  ***
##   starksmall    9.469 2.30          0   4.114        65.6       &lt;0.001  ***
##    starkaide   -0.483 1.86          0  -0.259        65.6        0.796</code></pre>
<p>In this estimating equation, the coefficients <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> represent treatment effects, or
differences in average math scores relative to the reference level of
<code>stark</code>, which in this case is a regular-size class. The
t-statistics and p-values reported by <code>coef_test</code> are
separate tests of the null hypotheses that each of these coefficients
are equal to zero, meaning that there is no difference between the
specified treatment condition and the reference level. We might want to
instead test the <em>joint</em> null hypothesis that there are no
differences among <em>any</em> of the conditions. This null can be
expressed by a set of multiple constraints on the parameters: <span class="math inline">\(\beta_1 = 0\)</span> and <span class="math inline">\(\beta_2 = 0\)</span>.</p>
<p>To test the null hypothesis that <span class="math inline">\(\beta_1
= \beta_2 = 0\)</span> based on the treatment effects model
specification, we can use:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>C_trt <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>C_trt</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    0    1    0
## [2,]    0    0    1</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_trt, <span class="at">constraints =</span> C_trt, <span class="at">vcov =</span> V_trt)</span></code></pre></div>
<pre><code>##  test Fstat df_num df_denom  p_val sig
##   HTZ  10.2      2     65.3 &lt;0.001 ***</code></pre>
<p>The result includes details about the form of <code>test</code>
computed, the <span class="math inline">\(F\)</span>-statistic, the
numerator and denominator degrees of freedom used to compute the
reference distribution, and the <span class="math inline">\(p\)</span>-value corresponding to the specified
null hypothesis. In this example, <span class="math inline">\(p =
0.000141\)</span>, so we can rule out the null hypothesis that there are
no differences in math performance across conditions.</p>
<p>The representation of null hypotheses as arbitrary constraint
matrices is useful for developing theory about how to test such
hypotheses, but it is not all that helpful for actually running
tests—constructing constraint matrices “by hand” is just too cumbersome
of an exercise. Moreover, <span class="math inline">\(\mathbf{C}\)</span> matrices typically follow one
of a small number of patterns. Two common use cases are a) constraining
a set of <span class="math inline">\(q &gt; 1\)</span> parameters to all
be equal to zero and b) constraining a set of <span class="math inline">\(q + 1\)</span> parameters to be equal to a common
value. The <code>clubSandwich</code> package now includes a set of
helper functions to create constraint matrices for these common use
cases.</p>
</div>
<div id="constrain_zero" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span>
<code>constrain_zero()</code></h2>
<p>To constrain a set of <span class="math inline">\(q\)</span>
regression coefficients to all be equal to zero, the simplest form of
the <span class="math inline">\(\mathbf{C}\)</span> matrix would consist
of a set of <span class="math inline">\(q\)</span> rows, where a single
entry in each row would be equal to 1 and the remaining entries would
all be zero. For the <code>lm_trt</code> model, the C matrix would look
like this: <span class="math display">\[
\mathbf{C} = \left[\begin{array}{ccc} 0 &amp; 1 &amp; 0 \\ 0 &amp; 0
&amp; 1 \end{array} \right],
\]</span> so that <span class="math display">\[
\mathbf{C}\boldsymbol\beta = \left[\begin{array}{ccc} 0 &amp; 1 &amp; 0
\\ 0 &amp; 0 &amp; 1 \end{array} \right] \left[\begin{array}{c} \beta_0
\\ \beta_1 \\ \beta_2 \end{array} \right] = \left[\begin{array}{c}
\beta_1 \\ \beta_2 \end{array} \right],
\]</span> which is set equal to <span class="math inline">\(\left[\begin{array}{c} 0 \\ 0 \end{array}
\right]\)</span>.</p>
<p>The <code>constrain_zero()</code> function will create matrices like
this automatically. The function takes two main arguments:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">args</span>(constrain_zero)</span></code></pre></div>
<pre><code>## function (constraints, coefs, reg_ex = FALSE) 
## NULL</code></pre>
<ul>
<li>The <code>constraints</code> argument is used to specify
<em>which</em> coefficients in a regression model to set equal to
zero.</li>
<li>The <code>coefs</code> argument is the set of estimated regression
coefficients, for which to calculate the constraints.</li>
</ul>
<p>Constraints can be specified by position index, by name, or via a
regular expression. To test the joint null hypothesis that average math
performance is equal across the three treatment conditions, we need to
constrain the second and third coefficients to zero:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">constrain_zero</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">coefs =</span> <span class="fu">coef</span>(lm_trt))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    0    1    0
## [2,]    0    0    1</code></pre>
<p>Or equivalently:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">constrain_zero</span>(<span class="fu">c</span>(<span class="st">&quot;starksmall&quot;</span>,<span class="st">&quot;starkaide&quot;</span>), <span class="at">coefs =</span> <span class="fu">coef</span>(lm_trt))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    0    1    0
## [2,]    0    0    1</code></pre>
<p>or</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">constrain_zero</span>(<span class="st">&quot;^stark&quot;</span>, <span class="at">coefs =</span> <span class="fu">coef</span>(lm_trt), <span class="at">reg_ex =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    0    1    0
## [2,]    0    0    1</code></pre>
<p>Note that if <code>constraints</code> is a regular expression, then
the <code>reg_ex</code> argument needs to be set to
<code>TRUE</code>.</p>
<p>The result of <code>constrain_zero()</code> can then be fed into the
<code>Wald_test()</code> function:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>C_trt <span class="ot">&lt;-</span> <span class="fu">constrain_zero</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">coefs =</span> <span class="fu">coef</span>(lm_trt))</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_trt, <span class="at">constraints =</span> C_trt, <span class="at">vcov =</span> V_trt)</span></code></pre></div>
<pre><code>##  test Fstat df_num df_denom  p_val sig
##   HTZ  10.2      2     65.3 &lt;0.001 ***</code></pre>
<p>To reduce redundancy in the syntax, we can also omit the
<code>coefs</code> argument to <code>constrain_zero</code>, so long as
we call it inside of <code>Wald_test</code><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_trt, <span class="at">constraints =</span> <span class="fu">constrain_zero</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>), <span class="at">vcov =</span> V_trt)</span></code></pre></div>
<pre><code>##  test Fstat df_num df_denom  p_val sig
##   HTZ  10.2      2     65.3 &lt;0.001 ***</code></pre>
</div>
<div id="constrain_equal" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span>
<code>constrain_equal()</code></h2>
<p>Another common type of constraints involve setting a set of <span class="math inline">\(q + 1\)</span> regression coefficients to be all
equal to a common (but unknown) value (<span class="math inline">\(q +
1\)</span> because it takes <span class="math inline">\(q\)</span>
constraints to do this). There are many equivalent ways to express such
a set of constraints in terms of a <span class="math inline">\(\mathbf{C}\)</span> matrix. One fairly simple form
consists of a set of <span class="math inline">\(q\)</span> rows, where
the entry corresponding to one of the coefficients of interest is equal
to -1 and the entry corresponding to another coefficient of interest is
equal to 1.</p>
<p>To see how this works, let’s look at a different way of
parameterizing our simple model for the STAR data, by using separate
intercepts for each treatment condition. The estimating equation would
then be <span class="math display">\[
\left(\text{Math}\right)_{ij} = \beta_0 \left(\text{regular}\right)_{ij}
+ \beta_1 \left(\text{small}\right)_{ij} + \beta_2
\left(\text{aide}\right)_{ij} + e_{ij}.
\]</span> This model can be estimated in R by dropping the intercept
term:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>lm_sep <span class="ot">&lt;-</span> <span class="fu">lm</span>(math1 <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> stark, <span class="at">data =</span> STAR)</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>V_sep <span class="ot">&lt;-</span> <span class="fu">vcovCR</span>(lm_sep, <span class="at">cluster =</span> STAR<span class="sc">$</span>schoolidk, <span class="at">type =</span> <span class="st">&quot;CR2&quot;</span>)</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="fu">coef_test</span>(lm_sep, <span class="at">vcov =</span> V_sep)</span></code></pre></div>
<pre><code>## Alternative hypothesis: two-sided 
##         Coef. Estimate   SE Null value t-stat d.f. (Satt) p-val (Satt) Sig.
##  starkregular      532 2.78          0    192        59.9       &lt;0.001  ***
##    starksmall      541 2.89          0    187        65.0       &lt;0.001  ***
##     starkaide      531 2.72          0    195        64.3       &lt;0.001  ***</code></pre>
<p>In this parameterization, the coefficients <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\beta_2\)</span> represent the average math
performance levels of students in each of the treatment conditions. The
t-tests and p-values now have a very different interpretation because
they pertain to the null hypothesis that the average performance level
for a given condition is equal to zero. With this separate-intercepts
model, the joint null hypothesis that performance levels are equal
across conditions amounts to constraining the intercepts to be equal to
each other: <span class="math inline">\(\beta_0 = \beta_1\)</span> and
<span class="math inline">\(\beta_0 = \beta_2\)</span> (note that we
don’t need the constraint <span class="math inline">\(\beta_1 =
\beta_2\)</span> because it is implied by the first two).</p>
<p>For the <code>lm_sep</code> model, which has separate intercepts
<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\beta_2\)</span>, the C matrix would look like
this: <span class="math display">\[
\mathbf{C} = \left[\begin{array}{ccc} -1 &amp; 1 &amp; 0 \\ -1 &amp; 0
&amp; 1 \end{array} \right],
\]</span> so that <span class="math display">\[
\mathbf{C}\boldsymbol\beta = \left[\begin{array}{ccc} -1 &amp; 1 &amp; 0
\\ -1 &amp; 0 &amp; 1 \end{array} \right] \left[\begin{array}{c} \beta_0
\\ \beta_1 \\ \beta_2 \end{array} \right] = \left[\begin{array}{c}
\beta_1 - \beta_0 \\ \beta_2 - \beta_0 \end{array} \right],
\]</span> which is set equal to <span class="math inline">\(\left[\begin{array}{c} 0 \\ 0 \end{array}
\right]\)</span>.</p>
<p>The <code>constrain_equal()</code> function will create matrices like
this automatically, given a set of coefficients to constrain. The syntax
is identical to <code>constrain_zero()</code>:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="fu">args</span>(constrain_equal)</span></code></pre></div>
<pre><code>## function (constraints, coefs, reg_ex = FALSE) 
## NULL</code></pre>
<p>To test the joint null hypothesis that average math performance is
equal across the three treatment conditions, we can constrain all three
coefficients of <code>lm_sep</code> to be equal:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="fu">constrain_equal</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">coefs =</span> <span class="fu">coef</span>(lm_sep))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]   -1    1    0
## [2,]   -1    0    1</code></pre>
<p>Or equivalently:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="fu">constrain_equal</span>(<span class="fu">c</span>(<span class="st">&quot;starkregular&quot;</span>,<span class="st">&quot;starksmall&quot;</span>,<span class="st">&quot;starkaide&quot;</span>), <span class="at">coefs =</span> <span class="fu">coef</span>(lm_sep))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]   -1    1    0
## [2,]   -1    0    1</code></pre>
<p>or</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="fu">constrain_equal</span>(<span class="st">&quot;^stark&quot;</span>, <span class="at">coefs =</span> <span class="fu">coef</span>(lm_sep), <span class="at">reg_ex =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]   -1    1    0
## [2,]   -1    0    1</code></pre>
<p>Just as with <code>constrain_zero</code>, if <code>constraints</code>
is a regular expression, then the <code>reg_ex</code> argument needs to
be set to <code>TRUE</code>.</p>
<p>This constraint matrix can then be fed into
<code>Wald_test()</code>:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>C_sep <span class="ot">&lt;-</span> <span class="fu">constrain_equal</span>(<span class="st">&quot;^stark&quot;</span>, <span class="at">coefs =</span> <span class="fu">coef</span>(lm_sep), <span class="at">reg_ex =</span> <span class="cn">TRUE</span>)</span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_sep, <span class="at">constraints =</span> C_sep, <span class="at">vcov =</span> V_sep)</span></code></pre></div>
<pre><code>##  test Fstat df_num df_denom  p_val sig
##   HTZ  10.2      2     65.3 &lt;0.001 ***</code></pre>
<p>or equivalently:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_sep, <span class="at">constraints =</span> <span class="fu">constrain_equal</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>), <span class="at">vcov =</span> V_sep)</span></code></pre></div>
<pre><code>##  test Fstat df_num df_denom  p_val sig
##   HTZ  10.2      2     65.3 &lt;0.001 ***</code></pre>
<p>Note that these test results are exactly equal to the tests based on
<code>lm_trt</code> with <code>constrain_zero()</code>. They’re
algebraically equivalent—just different ways of parameterizing the same
model and constraints.</p>
</div>
</div>
<div id="testing-an-interaction" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Testing an
interaction</h1>
<p>Let’s now consider how these functions can be applied in a more
complex model. Suppose that we are interested in understanding whether
the effect of being in a small class is consistent across schools in
different areas, where areas are categorized as urban, suburban, or
rural. To answer this question, we need to test for an interaction
between urbanicity and treatment condition. One estimating equation that
would let us examine this question is: <span class="math display">\[
\begin{aligned}
\left(\text{Math}\right)_{ij} &amp;= \beta_0 + \beta_1
\left(\text{suburban}\right)_{ij} + \beta_2
\left(\text{rural}\right)_{ij} \\
&amp; \quad + \beta_3 \left(\text{small}\right)_{ij} + \beta_4
\left(\text{aide}\right)_{ij} \\
&amp; \quad\quad + \beta_5
\left(\text{small}\right)(\text{suburban})_{ij} + \beta_6
\left(\text{aide}\right)(\text{suburban})_{ij} \\
&amp; \quad\quad\quad + \beta_{7}
\left(\text{small}\right)(\text{rural})_{ij} + \beta_{8}
\left(\text{aide}\right)(\text{rural})_{ij} \\
&amp; \quad\quad\quad\quad + \mathbf{x}_{ij} \boldsymbol\gamma  +
e_{ij},
\end{aligned}
\]</span> where <span class="math inline">\(\mathbf{x}_{ij}\)</span> is
a row vector of student characteristics, included just to make the
regression look fancier. In this specification, <span class="math inline">\(\beta_3\)</span> and <span class="math inline">\(\beta_4\)</span> represent the effects of being in
a small class or aide class, compared to being in a regular class, but
<em>only for the reference level of urbanicity</em>—in this case, urban
schools. The coefficients <span class="math inline">\(\beta_5, \beta_6,
\beta_7, \beta_8\)</span> all represent <em>interactions</em> between
treatment condition and urbanicity. Here’s the model, estimated in
R:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a>lm_urbanicity <span class="ot">&lt;-</span> <span class="fu">lm</span>(math1 <span class="sc">~</span> schoolk <span class="sc">*</span> stark <span class="sc">+</span> gender <span class="sc">+</span> ethnicity <span class="sc">+</span> lunchk, <span class="at">data =</span> STAR)</span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>V_urbanicity <span class="ot">&lt;-</span> <span class="fu">vcovCR</span>(lm_urbanicity, <span class="at">cluster =</span> STAR<span class="sc">$</span>schoolidk, <span class="at">type =</span> <span class="st">&quot;CR2&quot;</span>)</span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a><span class="fu">coef_test</span>(lm_urbanicity, <span class="at">vcov =</span> V_urbanicity)</span></code></pre></div>
<pre><code>## Alternative hypothesis: two-sided 
##                       Coef. Estimate    SE Null value  t-stat d.f. (Satt)
##                 (Intercept)   542.62  5.91          0 91.8599       21.70
##             schoolksuburban     2.77  6.76          0  0.4100       28.35
##                schoolkrural     1.03  6.38          0  0.1616       30.74
##                  starksmall     9.42  4.56          0  2.0649       17.10
##                   starkaide    -4.27  2.17          0 -1.9631       16.73
##                genderfemale     2.14  1.20          0  1.7773       67.14
##               ethnicityafam   -16.79  4.19          0 -4.0026       34.94
##              ethnicityasian    13.19 11.02          0  1.1963        6.23
##           ethnicityhispanic    39.23 20.62          0  1.9028        1.01
##              ethnicityother     8.86 18.78          0  0.4720        3.02
##                  lunchkfree   -19.37  2.04          0 -9.4848       57.38
##  schoolksuburban:starksmall     3.03  6.39          0  0.4746       28.94
##     schoolkrural:starksmall    -0.31  5.58          0 -0.0555       34.04
##   schoolksuburban:starkaide     5.10  3.72          0  1.3711       28.64
##      schoolkrural:starkaide     8.16  3.16          0  2.5857       34.30
##  p-val (Satt) Sig.
##        &lt;0.001  ***
##        0.6849     
##        0.8727     
##        0.0544    .
##        0.0665    .
##        0.0800    .
##        &lt;0.001  ***
##        0.2751     
##        0.3067     
##        0.6690     
##        &lt;0.001  ***
##        0.6386     
##        0.9560     
##        0.1810     
##        0.0141    *</code></pre>
<p>With this specification, there are several different null hypotheses
that we might want to test. For one, perhaps we want to see if there is
<em>any</em> variation in treatment effects across different levels of
urbanicity. This can be expressed in the null hypothesis that all four
interaction terms are zero, or <span class="math inline">\(H_{0A}:
\beta_5 = \beta_6 = \beta_7 = \beta_8 = 0\)</span>. With Wald test:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_urbanicity, </span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a>          <span class="at">constraints =</span> <span class="fu">constrain_zero</span>(<span class="st">&quot;schoolk.+:stark&quot;</span>, <span class="at">reg_ex =</span> <span class="cn">TRUE</span>),</span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a>          <span class="at">vcov =</span> V_urbanicity)</span></code></pre></div>
<pre><code>##  test Fstat df_num df_denom p_val sig
##   HTZ  1.96      4     37.5 0.121</code></pre>
<p>Another possibility is that we might want to focus on variation in
the effect of being in a small class or regular class, while ignoring
whatever is going on in the aide class condition. Here, the null
hypothesis would be simply <span class="math inline">\(H_{0B}: \beta_5 =
\beta_6 = 0\)</span>, tested as:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_urbanicity, </span>
<span id="cb41-2"><a href="#cb41-2" tabindex="-1"></a>          <span class="at">constraints =</span> <span class="fu">constrain_zero</span>(<span class="st">&quot;schoolk.+:starksmall&quot;</span>, <span class="at">reg_ex =</span> <span class="cn">TRUE</span>),</span>
<span id="cb41-3"><a href="#cb41-3" tabindex="-1"></a>          <span class="at">vcov =</span> V_urbanicity)</span></code></pre></div>
<pre><code>##  test Fstat df_num df_denom p_val sig
##   HTZ 0.189      2     34.5 0.828</code></pre>
<div id="lists-of-constraints" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Lists of
constraints</h2>
<p>In models like the urbanicity-by-treatment interaction specification,
we may need to run multiple tests on the same estimating equation. This
can be accomplished with <code>Wald_test</code> by providing a
<em>list</em> of constraints to the <code>constraints</code> argument.
For example, we could test the hypotheses described above by creating a
list of several constraint matrices and then passing it to
<code>Wald_test</code>:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a>C_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a>  <span class="st">`</span><span class="at">Any interaction</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">constrain_zero</span>(<span class="st">&quot;schoolk.+:stark&quot;</span>, </span>
<span id="cb43-3"><a href="#cb43-3" tabindex="-1"></a>                                     <span class="fu">coef</span>(lm_urbanicity), <span class="at">reg_ex =</span> <span class="cn">TRUE</span>),</span>
<span id="cb43-4"><a href="#cb43-4" tabindex="-1"></a>  <span class="st">`</span><span class="at">Small vs regular</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">constrain_zero</span>(<span class="st">&quot;schoolk.+:starksmall&quot;</span>, </span>
<span id="cb43-5"><a href="#cb43-5" tabindex="-1"></a>                                      <span class="fu">coef</span>(lm_urbanicity), <span class="at">reg_ex =</span> <span class="cn">TRUE</span>)</span>
<span id="cb43-6"><a href="#cb43-6" tabindex="-1"></a>)</span>
<span id="cb43-7"><a href="#cb43-7" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_urbanicity, </span>
<span id="cb43-9"><a href="#cb43-9" tabindex="-1"></a>          <span class="at">constraints =</span> C_list,</span>
<span id="cb43-10"><a href="#cb43-10" tabindex="-1"></a>          <span class="at">vcov =</span> V_urbanicity)</span></code></pre></div>
<pre><code>## $`Any interaction`
##  test Fstat df_num df_denom p_val sig
##   HTZ  1.96      4     37.5 0.121    
## 
## $`Small vs regular`
##  test Fstat df_num df_denom p_val sig
##   HTZ 0.189      2     34.5 0.828</code></pre>
<p>Setting the option <code>tidy = TRUE</code> will arrange the output
of all the tests into a single data frame:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_urbanicity, </span>
<span id="cb45-2"><a href="#cb45-2" tabindex="-1"></a>          <span class="at">constraints =</span> C_list,</span>
<span id="cb45-3"><a href="#cb45-3" tabindex="-1"></a>          <span class="at">vcov =</span> V_urbanicity, </span>
<span id="cb45-4"><a href="#cb45-4" tabindex="-1"></a>          <span class="at">tidy =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##        hypothesis test Fstat df_num df_denom p_val sig
##   Any interaction  HTZ 1.960      4     37.5 0.121    
##  Small vs regular  HTZ 0.189      2     34.5 0.828</code></pre>
<p>The list of constraints can also be created inside
<code>Wald_test</code>, so that the <code>coefs</code> argument can be
omitted from <code>constrain_zero()</code>:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" tabindex="-1"></a><span class="fu">Wald_test</span>(</span>
<span id="cb47-2"><a href="#cb47-2" tabindex="-1"></a>  lm_urbanicity, </span>
<span id="cb47-3"><a href="#cb47-3" tabindex="-1"></a>  <span class="at">constraints =</span> <span class="fu">list</span>(</span>
<span id="cb47-4"><a href="#cb47-4" tabindex="-1"></a>    <span class="st">`</span><span class="at">Any interaction</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">constrain_zero</span>(<span class="st">&quot;schoolk.+:stark&quot;</span>, <span class="at">reg_ex =</span> <span class="cn">TRUE</span>),</span>
<span id="cb47-5"><a href="#cb47-5" tabindex="-1"></a>    <span class="st">`</span><span class="at">Small vs regular</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">constrain_zero</span>(<span class="st">&quot;schoolk.+:starksmall&quot;</span>, <span class="at">reg_ex =</span> <span class="cn">TRUE</span>)</span>
<span id="cb47-6"><a href="#cb47-6" tabindex="-1"></a>  ),</span>
<span id="cb47-7"><a href="#cb47-7" tabindex="-1"></a>  <span class="at">vcov =</span> V_urbanicity, </span>
<span id="cb47-8"><a href="#cb47-8" tabindex="-1"></a>  <span class="at">tidy =</span> <span class="cn">TRUE</span></span>
<span id="cb47-9"><a href="#cb47-9" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>##        hypothesis test Fstat df_num df_denom p_val sig
##   Any interaction  HTZ 1.960      4     37.5 0.121    
##  Small vs regular  HTZ 0.189      2     34.5 0.828</code></pre>
</div>
</div>
<div id="pairwise-t-tests" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Pairwise t-tests</h1>
<p>The <code>clubSandwich</code> package also provides a further
convenience function, <code>constrain_pairwise()</code> that can be used
in combination with <code>Wald_test()</code> to conduct pairwise
comparisons among a set of regression coefficients. This function
differs from the other two <code>constrain_*()</code> functions because
it returns a <em>list</em> of constraint matrices, each of which
corresponds to a single linear combination of covariates. Specifically,
the <code>constrain_pairwise()</code> function provides a list of
constraints that represent the differences between every possible pair
among a specified set of coefficients. The syntax is very similar to the
other <code>constrain_*()</code> functions.</p>
<p>To demonstrate, consider the separate-intercepts specification of the
simpler regression model:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a><span class="fu">coef_test</span>(lm_sep, <span class="at">vcov =</span> V_sep)</span></code></pre></div>
<pre><code>## Alternative hypothesis: two-sided 
##         Coef. Estimate   SE Null value t-stat d.f. (Satt) p-val (Satt) Sig.
##  starkregular      532 2.78          0    192        59.9       &lt;0.001  ***
##    starksmall      541 2.89          0    187        65.0       &lt;0.001  ***
##     starkaide      531 2.72          0    195        64.3       &lt;0.001  ***</code></pre>
<p>This specification is nice because it lets us simply read off the
average outcomes for each group. However, we will naturally also want to
know about whether there are differences between the groups, so we’ll
want to compare the small-class condition to the regular-size class
condition, the aide condition to the regular-size class condition, and
the small-class condition to the aide condition. Thus, we’ll want
comparisons among all three coefficients:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a>C_pairs <span class="ot">&lt;-</span> <span class="fu">constrain_pairwise</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">coefs =</span> <span class="fu">coef</span>(lm_sep))</span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a>C_pairs</span></code></pre></div>
<pre><code>## $`starksmall - starkregular`
##      [,1] [,2] [,3]
## [1,]   -1    1    0
## 
## $`starkaide - starkregular`
##      [,1] [,2] [,3]
## [1,]   -1    0    1
## 
## $`starkaide - starksmall`
##      [,1] [,2] [,3]
## [1,]    0   -1    1</code></pre>
<p>Feeding these constraints into <code>Wald_test()</code> gives us
significance tests for each pair:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_sep, <span class="at">constraints =</span> C_pairs, <span class="at">vcov =</span> V_sep, <span class="at">tidy =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##                 hypothesis test   Fstat df_num df_denom  p_val sig
##  starksmall - starkregular  HTZ 16.9238      1     65.6 &lt;0.001 ***
##   starkaide - starkregular  HTZ  0.0673      1     65.6  0.796    
##     starkaide - starksmall  HTZ 17.8137      1     66.9 &lt;0.001 ***</code></pre>
<p>The first two of these tests are equivalent to the tests of the
treatment effect coefficients in the other parameterization of the
model. Indeed, the denominator degrees of freedom are identical to the
results of <code>coef_test(lm_trt, vcov = V_trt)</code>; the
<code>Fstat</code>s here are equal to the squared t-statistics from the
first model:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" tabindex="-1"></a>t_stats <span class="ot">&lt;-</span> <span class="fu">coef_test</span>(lm_trt, <span class="at">vcov =</span> V_trt)<span class="sc">$</span>tstat[<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb55-2"><a href="#cb55-2" tabindex="-1"></a>F_stats <span class="ot">&lt;-</span> <span class="fu">Wald_test</span>(lm_sep, <span class="at">constraints =</span> C_pairs, <span class="at">vcov =</span> V_sep, <span class="at">tidy =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>Fstat[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span>
<span id="cb55-3"><a href="#cb55-3" tabindex="-1"></a><span class="fu">all.equal</span>(t_stats<span class="sc">^</span><span class="dv">2</span>, F_stats)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>It is important to note that the p-values from the pairwise
comparisons are <em>not</em> corrected for multiplicity.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> For now, please
correct-your-own using <code>p.adjust()</code> or your preferred
method.</p>
<p>Pairwise comparisons might also be of use in the model with
treatment-by-urbanicity interactions. Here’s the model results
again:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" tabindex="-1"></a><span class="fu">coef_test</span>(lm_urbanicity, <span class="at">vcov =</span> V_urbanicity)</span></code></pre></div>
<pre><code>## Alternative hypothesis: two-sided 
##                       Coef. Estimate    SE Null value  t-stat d.f. (Satt)
##                 (Intercept)   542.62  5.91          0 91.8599       21.70
##             schoolksuburban     2.77  6.76          0  0.4100       28.35
##                schoolkrural     1.03  6.38          0  0.1616       30.74
##                  starksmall     9.42  4.56          0  2.0649       17.10
##                   starkaide    -4.27  2.17          0 -1.9631       16.73
##                genderfemale     2.14  1.20          0  1.7773       67.14
##               ethnicityafam   -16.79  4.19          0 -4.0026       34.94
##              ethnicityasian    13.19 11.02          0  1.1963        6.23
##           ethnicityhispanic    39.23 20.62          0  1.9028        1.01
##              ethnicityother     8.86 18.78          0  0.4720        3.02
##                  lunchkfree   -19.37  2.04          0 -9.4848       57.38
##  schoolksuburban:starksmall     3.03  6.39          0  0.4746       28.94
##     schoolkrural:starksmall    -0.31  5.58          0 -0.0555       34.04
##   schoolksuburban:starkaide     5.10  3.72          0  1.3711       28.64
##      schoolkrural:starkaide     8.16  3.16          0  2.5857       34.30
##  p-val (Satt) Sig.
##        &lt;0.001  ***
##        0.6849     
##        0.8727     
##        0.0544    .
##        0.0665    .
##        0.0800    .
##        &lt;0.001  ***
##        0.2751     
##        0.3067     
##        0.6690     
##        &lt;0.001  ***
##        0.6386     
##        0.9560     
##        0.1810     
##        0.0141    *</code></pre>
<p>Suppose that we are interested in the effect of small versus regular
size classes, and in particular whether this effect varies across
schools in different areas. The coefficients on
<code>schoolksuburban:starksmall</code> and
<code>schoolkrural:starksmall</code> already give us the differences in
treatment effects between suburban schools versus urban schools and
between rural schools versus urban schools. The difference between these
coefficients gives us the difference in treatment effects between
suburban schools and rural schools. We can look at all three of these
contrasts using <code>constrain_pairwise()</code> by setting the option
<code>with_zero = TRUE</code>:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" tabindex="-1"></a><span class="fu">Wald_test</span>(lm_urbanicity, </span>
<span id="cb59-2"><a href="#cb59-2" tabindex="-1"></a>          <span class="at">constraints =</span> <span class="fu">constrain_pairwise</span>(<span class="st">&quot;:starksmall&quot;</span>, <span class="at">reg_ex =</span> <span class="cn">TRUE</span>, <span class="at">with_zero =</span> <span class="cn">TRUE</span>),</span>
<span id="cb59-3"><a href="#cb59-3" tabindex="-1"></a>          <span class="at">vcov =</span> V_urbanicity,</span>
<span id="cb59-4"><a href="#cb59-4" tabindex="-1"></a>          <span class="at">tidy =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##                                            hypothesis test   Fstat df_num
##                            schoolksuburban:starksmall  HTZ 0.22526      1
##                               schoolkrural:starksmall  HTZ 0.00308      1
##  schoolkrural:starksmall - schoolksuburban:starksmall  HTZ 0.36471      1
##  df_denom p_val sig
##      28.9 0.639    
##      34.0 0.956    
##      24.4 0.551</code></pre>
<p>Again, the results of the first two tests are identical to the
t-tests reported in <code>coef_test()</code>.</p>
</div>
<div id="remark" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Remark</h1>
<p>All of the preceding examples were based on ordinary linear
regression models with clustered standard errors. However,
<code>Wald_test()</code> and its helper functions all work identically
for all of the other models with supporting <code>clubSandwich</code>
methods, including <code>nlme::lme()</code>, <code>nlme::gls()</code>,
<code>lme4::lmer()</code>, <code>rma.uni()</code>,
<code>rma.mv()</code>, and <code>robu()</code>, among others.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0" line-spacing="2">
<div id="ref-pustejovsky2018small" class="csl-entry">
Pustejovsky, J. E., &amp; Tipton, E. (2018). Small-<span>Sample</span>
<span>Methods</span> for <span>Cluster</span>-<span>Robust</span>
<span>Variance</span> <span>Estimation</span> and
<span>Hypothesis</span> <span>Testing</span> in <span>Fixed</span>
<span>Effects</span> <span>Models</span>. <em>Journal of Business &amp;
Economic Statistics</em>, <em>36</em>(4), 672–683. <a href="https://doi.org/10.1080/07350015.2016.1247004">https://doi.org/10.1080/07350015.2016.1247004</a>
</div>
<div id="ref-tipton2015small" class="csl-entry">
Tipton, E., &amp; Pustejovsky, J. E. (2015). Small-sample adjustments
for tests of moderators and model fit using robust variance estimation
in meta-regression. <em>Journal of Educational and Behavioral
Statistics</em>, <em>40</em>(6), 604–634. <a href="https://doi.org/10.3102/1076998615606099">https://doi.org/10.3102/1076998615606099</a>
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>In <span class="citation">Pustejovsky &amp; Tipton
(2018)</span> we used a more general formulation of multiple-constraint
null hypotheses, expressed as <span class="math inline">\(H_0:
\mathbf{C} \boldsymbol\beta = \mathbf{d}\)</span> for some fixed <span class="math inline">\(q \times 1\)</span> vector <span class="math inline">\(\mathbf{d}\)</span>. In practice, it’s often
possible to modify the <span class="math inline">\(\mathbf{C}\)</span>
matrix so that <span class="math inline">\(\mathbf{d}\)</span> can
always be set to <span class="math inline">\(\mathbf{0}\)</span>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>How does this work? If we omit the <code>coefs</code>
argument, <code>constrain_zero()</code> acts as a functional, by
returning a function equivalent to
<code>function(coefs) constrain_zero(constraints, coefs = coefs)</code>.
If this function is fed into the <code>constraints</code> argument of
<code>Wald_test()</code>, <code>Wald_test()</code> recognizes that it is
a function and evaluates the function with <code>coef(obj)</code>. It’s
a kinda-sorta hacky substitute for lazy evaluation. If you have
suggestions for how to do this more elegantly, please send them my
way.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Options to include multiplicity corrections (Bonferroni,
Holm, Benjamini-Hochberg, etc.) might be included in a <a href="https://github.com/jepusto/clubSandwich/issues/33">future
release</a>. Reach out if this is of interest to you.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
